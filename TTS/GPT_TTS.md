ì¢‹ìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” **OpenAI API í‚¤ì™€ Google Cloud ì„œë¹„ìŠ¤ ê³„ì • í‚¤ JSON íŒŒì¼ì„ ì‚¬ìš©í•œ TTS í”„ë¡œì íŠ¸**ë¥¼ ë””ë ‰í† ë¦¬ êµ¬ì„±ê¹Œì§€ í¬í•¨í•´ **VSCode í™˜ê²½ ê¸°ì¤€ Git í”„ë¡œì íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

---

## âœ… 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ì˜ˆì‹œ

```
My_project/
â”œâ”€â”€ .env                   â† OpenAI API í‚¤ ì €ì¥
â”œâ”€â”€ .gitignore             â† ë¯¼ê° ì •ë³´ ë¬´ì‹œ ì„¤ì •
â”œâ”€â”€ README.md              â† í”„ë¡œì íŠ¸ ì„¤ëª… ë¬¸ì„œ
â”œâ”€â”€ test_gpt_voice.py      â† ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
â””â”€â”€ requirements.txt       â† í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª…ì‹œ
```

---

## âœ… 2. `.gitignore`

```gitignore
.env
*.json
__pycache__/
*.pyc
*.mp3
.venv/
```

> `.env` íŒŒì¼ê³¼ Google Cloud JSON í‚¤ íŒŒì¼ì€ **ì ˆëŒ€ Gitì— ì˜¬ë¦¬ì§€ ë§ˆì„¸ìš”**. ìœ„ì²˜ëŸ¼ `.gitignore`ì— ì¶”ê°€í•´ì•¼ ì•ˆì „í•©ë‹ˆë‹¤.

---

## âœ… 3. `.env` íŒŒì¼ (ì—…ë¡œë“œ ê¸ˆì§€)

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

## âœ… 4. `requirements.txt` íŒŒì¼

```txt
openai>=1.0.0
google-cloud-texttospeech
python-dotenv
```

> ì•„ë˜ ëª…ë ¹ì–´ë¡œ ìë™ ìƒì„± ê°€ëŠ¥:

```bash
pip freeze > requirements.txt
```

---

## âœ… 5. `test_gpt_voice.py`

```python
import os
from openai import OpenAI
from google.cloud import texttospeech
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI()

# ChatGPT ì‘ë‹µ ë°›ê¸°
def get_chatgpt_response(prompt: str) -> str:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# í•œêµ­ì–´ ìŒì„±ìœ¼ë¡œ MP3 ë³€í™˜
def text_to_korean_speech(text: str, filename: str = "output_korean.mp3"):
    tts_client = texttospeech.TextToSpeechClient()

    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice = texttospeech.VoiceSelectionParams(
        language_code="ko-KR",
        name="ko-KR-Wavenet-C",
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0
    )

    response = tts_client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    with open(filename, "wb") as out:
        out.write(response.audio_content)
        print(f"âœ… í•œêµ­ì–´ ìŒì„± MP3 ì €ì¥ ì™„ë£Œ: {filename}")

if __name__ == "__main__":
    # Google ì„œë¹„ìŠ¤ í‚¤ ê²½ë¡œ ìˆ˜ë™ ì„¤ì •
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "ê²½ë¡œ\your-key.json"

    user_prompt = input("ğŸ’¬ ChatGPTì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš” (í•œê¸€): ")
    answer = get_chatgpt_response(user_prompt)
    print("ğŸ§  ChatGPT ì‘ë‹µ:", answer)

    text_to_korean_speech(answer)
```



## ğŸ” í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

1. `.env` íŒŒì¼ ìƒì„±:

```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx
```

2. Google Cloud Consoleì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • í‚¤(JSON)ë¥¼ ìƒì„±í•˜ì—¬ ë¡œì»¬ì— ì €ì¥í•˜ê³ ,
   `test_gpt_voice.py`ì˜ ê²½ë¡œë¥¼ ì•„ë˜ì²˜ëŸ¼ ìˆ˜ì •:

```python
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "ê²½ë¡œ\your-key.json"
```

## â–¶ï¸ ì‹¤í–‰

```bash
python test_gpt_voice.py
```

---

## â—ì£¼ì˜

* `.env`ì™€ JSON í‚¤ íŒŒì¼ì€ `.gitignore`ì— ì¶”ê°€ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤!
* API í‚¤ë¥¼ ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.

---

## ğŸ¯ ëª©í‘œ ê¸°ëŠ¥ (í•„ìš” ì‹œ ì¶”ê°€)

* í•œêµ­ì–´/ì˜ì–´ ìë™ ê°ì§€ ë° ìŒì„± ì„ íƒ
* ë‹¤íšŒ ì…ë ¥ ì§€ì›
* ìŒì„± ì¬ìƒ ê¸°ëŠ¥ ì¶”ê°€ (playsound ë“±)


ì‹¤í–‰ê²°ê³¼
![image](https://github.com/user-attachments/assets/67ece3b9-b01e-4b76-9078-e63c03b1c7df)

https://github.com/user-attachments/assets/9616ca02-8b29-4889-9825-8f660aea728e



